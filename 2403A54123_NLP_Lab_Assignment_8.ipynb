{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOimb3l25ZXcxq4SvAXZhNn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a54123-web/NLP/blob/main/2403A54123_NLP_Lab_Assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5A7DCAdcrY2",
        "outputId": "bdc03c19-0944-4fe1-86c6-5484f83e5f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "from collections import Counter, defaultdict\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Natural language processing is a field of artificial intelligence.\n",
        "It focuses on interaction between computers and humans.\n",
        "Language models help machines understand text.\n",
        "N-gram models are simple but useful language models.\n",
        "They predict words based on previous context.\n",
        "\"\"\"\n",
        "\n",
        "print(text[:300])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty7KIJ6ecwbP",
        "outputId": "ba53bbe3-bb9d-4b0b-f0eb-c0ca3777a0ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural language processing is a field of artificial intelligence.\n",
            "It focuses on interaction between computers and humans.\n",
            "Language models help machines understand text.\n",
            "N-gram models are simple but useful language models.\n",
            "They predict words based on previous context.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "\n",
        "    text = re.sub(r'[0-9]', '', text)  # remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    processed_sentences = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        words = word_tokenize(sent)\n",
        "        words = [w for w in words if w not in stop_words]\n",
        "\n",
        "        words = ['<s>'] + words + ['</s>']  # start/end tokens\n",
        "        processed_sentences.append(words)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "processed_data = preprocess_text(text)\n",
        "processed_data[:2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19d5CHLJc0ue",
        "outputId": "31335f39-f7ce-40cd-dc87-7ebab17e85cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<s>',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  'field',\n",
              "  'artificial',\n",
              "  'intelligence',\n",
              "  'focuses',\n",
              "  'interaction',\n",
              "  'computers',\n",
              "  'humans',\n",
              "  'language',\n",
              "  'models',\n",
              "  'help',\n",
              "  'machines',\n",
              "  'understand',\n",
              "  'text',\n",
              "  'ngram',\n",
              "  'models',\n",
              "  'simple',\n",
              "  'useful',\n",
              "  'language',\n",
              "  'models',\n",
              "  'predict',\n",
              "  'words',\n",
              "  'based',\n",
              "  'previous',\n",
              "  'context',\n",
              "  '</s>']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngrams(data, n):\n",
        "    ngrams = []\n",
        "    for sentence in data:\n",
        "        for i in range(len(sentence)-n+1):\n",
        "            ngrams.append(tuple(sentence[i:i+n]))\n",
        "    return Counter(ngrams)\n",
        "\n",
        "unigram = build_ngrams(processed_data, 1)\n",
        "bigram = build_ngrams(processed_data, 2)\n",
        "trigram = build_ngrams(processed_data, 3)\n",
        "\n",
        "print(\"Unigram sample:\", list(unigram.items())[:5])\n",
        "print(\"Bigram sample:\", list(bigram.items())[:5])\n",
        "print(\"Trigram sample:\", list(trigram.items())[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_8KLm80c9Ia",
        "outputId": "a682e39e-593c-4842-adeb-1363af2ebabd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram sample: [(('<s>',), 1), (('natural',), 1), (('language',), 3), (('processing',), 1), (('field',), 1)]\n",
            "Bigram sample: [(('<s>', 'natural'), 1), (('natural', 'language'), 1), (('language', 'processing'), 1), (('processing', 'field'), 1), (('field', 'artificial'), 1)]\n",
            "Trigram sample: [(('<s>', 'natural', 'language'), 1), (('natural', 'language', 'processing'), 1), (('language', 'processing', 'field'), 1), (('processing', 'field', 'artificial'), 1), (('field', 'artificial', 'intelligence'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_prob(w1, w2):\n",
        "    return bigram[(w1, w2)] / unigram[(w1,)]\n"
      ],
      "metadata": {
        "id": "7XSF9VNndFcT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V = len(unigram)\n",
        "\n",
        "def laplace_bigram_prob(w1, w2):\n",
        "    return (bigram[(w1, w2)] + 1) / (unigram[(w1,)] + V)\n"
      ],
      "metadata": {
        "id": "UrYQxCP7dIkU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"language models predict words\",\n",
        "    \"natural language processing field\",\n",
        "    \"computers understand language\",\n",
        "    \"artificial intelligence models\",\n",
        "    \"text prediction useful\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "d2Nv3l1CdLAh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_bigram_prob(sentence):\n",
        "    words = ['<s>'] + sentence.lower().split() + ['</s>']\n",
        "    prob = 1\n",
        "\n",
        "    for i in range(len(words)-1):\n",
        "        prob *= laplace_bigram_prob(words[i], words[i+1])\n",
        "\n",
        "    return prob\n",
        "\n",
        "for s in sentences:\n",
        "    print(s, sentence_bigram_prob(s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRzQEoYcdNrb",
        "outputId": "12f82ae3-4cb3-45ba-b335-78bd5c743d33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language models predict words 8.708535758408963e-07\n",
            "natural language processing field 1.2504564165920563e-06\n",
            "computers understand language 2.0319916769620914e-06\n",
            "artificial intelligence models 4.063983353924183e-06\n",
            "text prediction useful 2.2758306781975425e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence):\n",
        "    words = ['<s>'] + sentence.lower().split() + ['</s>']\n",
        "    N = len(words)\n",
        "    prob = sentence_bigram_prob(sentence)\n",
        "\n",
        "    return pow(1/prob, 1/N)\n",
        "\n",
        "for s in sentences:\n",
        "    print(s, perplexity(s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZl4ux8zdRBE",
        "outputId": "b4ea8306-64df-4103-f182-f4eefc70717a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language models predict words 10.233145364207008\n",
            "natural language processing field 9.634338626235857\n",
            "computers understand language 13.75357547490397\n",
            "artificial intelligence models 11.973182877013409\n",
            "text prediction useful 13.44534685946749\n"
          ]
        }
      ]
    }
  ]
}